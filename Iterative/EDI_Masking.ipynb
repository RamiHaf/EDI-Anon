{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "from true_classify import *\n",
    "from Utils import *\n",
    "from anonymization_methods import *\n",
    "from datasets import *\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from collections import Counter\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d283082",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75addd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing data directories\n",
    "\n",
    "source_path = 'Path of the Data to be anonimyzed'\n",
    "\n",
    "class_names = [folder for folder in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, folder))]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "file_list = os.listdir(source_path)\n",
    "model_dir = 'Path of the trained FR model'\n",
    "\n",
    "output_path = 'Path to save the anonimyzed images'\n",
    "\n",
    "save_roc_dir = 'Path to save the ROC'\n",
    "excel_file_path = 'Path to save the excel file with the numberical results of accuracy and f1_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a64045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new transform with additional data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and load the pretrained model\n",
    "\n",
    "model = models.convnext_base(pretrained=True)\n",
    "model.classifier[2]=nn.Linear(1024,num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('Path of the trained FR model.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameter to be used by the EDI_Anon to calculate the loss in order to anonimyze the images\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the q which in 100-the percentage of the affect onn the images\n",
    "q=99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to save the ROC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, dataset_name, save_dir):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "\n",
    "    # Plot macro-average ROC curve\n",
    "    plt.plot(fpr['micro'], tpr['micro'], color='deeppink', linestyle=':', lw=lw,\n",
    "             label='Macro-average ROC curve (area = {0:0.2f})'.format(roc_auc['micro']))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC for ' + dataset_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, f'ROC_{dataset_name}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw the images the circle on the images\n",
    "def draw_points_on_image(image, important_pixels_mask, point_size, point_color):\n",
    "    image = image.to(device)\n",
    "    important_pixels_mask = important_pixels_mask.to(device)\n",
    "\n",
    "    # Apply the mask directly on the GPU tensors\n",
    "    y_indices, x_indices = torch.nonzero(important_pixels_mask, as_tuple=True)\n",
    "    \n",
    "    image_pil = transforms.ToPILImage()(image.squeeze().cpu())\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "\n",
    "    for y, x in zip(y_indices, x_indices):\n",
    "        x, y = x.item(), y.item()\n",
    "        x0, y0 = x - point_size, y - point_size\n",
    "        x1, y1 = x + point_size, y + point_size\n",
    "        bbox = [(x0, y0), (x1, y1)]\n",
    "\n",
    "\n",
    "        draw.ellipse(bbox, fill = 'black', outline ='black')\n",
    "\n",
    "\n",
    "    return transforms.ToTensor()(image_pil).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f57f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the size of the circle to be drawen on the images\n",
    "pixel_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489af996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the original accuracy and f1_score of the original data\n",
    "\n",
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "new_test_path = source_path \n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "end_time = time.time()\n",
    "\n",
    "acc_time = end_time - start_time\n",
    "\n",
    "print(f\"Acc time is\", acc_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Setting high number of iteration to give the EDI_Anon the time it needs to effectivly anonimyze the dataset\n",
    "for itera in range(0,2000000):\n",
    "    # Iterate through all correct examples\n",
    "    for i in tqdm(range(len(correct_examples))):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "\n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "\n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "\n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "\n",
    "        # test if the image is correctly classified then we need to anonimyze it\n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "            \n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "            # Call the draw_dots_on_image function\n",
    "            annonymized_image = draw_points_on_image(annonymized_image, optimized_gradients[0, 0, :, :] >= 1, point_size=0.05,\n",
    "                                                     point_color=(0, 0, 0))\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            numpy_image = annonymized_image.cpu().detach().numpy().squeeze()\n",
    "            cv2_image = np.transpose(numpy_image, (1, 2, 0))\n",
    "            cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)\n",
    "            cv2_image = cv2_image*255\n",
    "            save_image(cv2_image, i, correct_label, class_output_path, pixel_size, 100-q)   \n",
    "\n",
    "        # If the model didn't correctly calssify the image then save it as it is\n",
    "        else:\n",
    "            numpy_image = annonymized_image.cpu().detach().numpy().squeeze()\n",
    "            cv2_image = np.transpose(numpy_image, (1, 2, 0))\n",
    "            cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)\n",
    "            cv2_image = cv2_image*255\n",
    "            save_image(cv2_image, i, correct_label, class_output_path, pixel_size, 100-q) \n",
    "\n",
    "    \n",
    "    # test the model performance on the anonimyzed data at the end of each iteration\n",
    "    our_test_loader = create_test_loader(iteration_out_path, batch_size=1)\n",
    "    accuracy, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "    print(f\"\\nAccuracy: {accuracy*100} %\")\n",
    "\n",
    "    # If we have achieved the requiered RIR, then end the EDI_Anon processes\n",
    "    if(accuracy*100 < 1):\n",
    "        break\n",
    "end_time = time.time()\n",
    "Anon_execution_time = end_time - start_time\n",
    "print(f\"\\nAnon Time: {Anon_execution_time} seconds\")\n",
    "print(f\"All images processed for iteration number {itera}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61712f71-9fbb-4c1e-95ca-f82130a216c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6ee46-fda5-4457-86fe-c882172ee13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
